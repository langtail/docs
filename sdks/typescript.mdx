---
title: 'TypeScript SDK'
---

Langtail's TypeScript SDK wraps OpenAI's API client so that it can be used seamlessly with Langtail. You can store the entire prompt in Langtail and reference it by prompt slug and environment. By routing requests through Langtail, you can get logs, metrics, and many more beneifts.

For more, check out the [GitHub repository](https://github.com/langtail/langtail-node).

## Installation

Use NPM or your package manager of choice to install the `langtail` package:

```bash
npm i langtail
```

## Usage

Here are the different ways you can use the SDK.

### 1. Invoke a prompt that's deployed on Langtail (recommended)

To invoke a deployed prompt, you can use `lt.prompts.invoke` like this:

```ts
const deployedPromptCompletion = await lt.prompts.invoke({
  prompt: "<PROMPT_SLUG>", // required
  environment: "staging",
  variables: {
    about: "cowboy Bebop",
  },
}) // results in an openAI ChatCompletion
```

If you call a prompt that isn't deployed yet, you will get an error thrown an error: `Error: Failed to fetch prompt: 404 {"error":"Prompt deployment not found"}`

### 2. Invoke a prompt that's stored in code

If you're storing your prompt in your codebase and want to give Langtail a try, use this method. You can use `lt.chat.completions.create` as a light wrapper over the OpenAI API that still sends logs and metrics to Langtail.

For more, [see the example in this doc](/proxy/integrate-sdk).

### 3. Fetch prompt from Langtail and invoke directly (proxyless)

If you're storing your prompt in Langtail but want to invoke it directly from your code without using Langtail as a proxy, use this method.

You can call `LangtailPrompts.get` to retrieve the contents of the prompt:

```ts
import { LangtailPrompts } from "langtail"

const lt = new LangtailPrompts({
  apiKey: "<LANGTAIL_API_KEY>",
})

const playgroundState = await lt.get({
  prompt: "<PROMPT_SLUG>",
  environment: "preview",
  version: "<PROMPT_VERSION>", // optional
})
```

The response will return something like this:

```json
{
  "chatInput": {
    "optionalExtra": "",
  },
  "state": {
    "args": {
      "frequency_penalty": 0,
      "jsonmode": false,
      "max_tokens": 800,
      "model": "gpt-3.5-turbo",
      "presence_penalty": 0,
      "stop": [],
      "stream": true,
      "temperature": 0.5,
      "top_p": 1,
    },
    "functions": [],
    "template": [
      {
        "content": "I want you to tell me a joke. Topic of the joke: {{topic}}",
        "role": "system",
      },
    ],
    "tools": [],
    "type": "chat",
  },
}
```

Now you can build the final output:

```ts
const openAiBody = lt.build(playgroundState, {
  stream: true,
  variables: {
    topic: "iron man",
  },
})
```

Which returns this object:

```js
{
  "frequency_penalty": 0,
  "max_tokens": 800,
  "messages": [
    {
      "content": "I want you to tell me a joke. Topic of the joke: iron man",
      "role": "system",
    },
  ],
  "model": "gpt-3.5-turbo",
  "presence_penalty": 0,
  "temperature": 0.5,
  "top_p": 1,
}
```

Finally, you can directly call the OpenAI SDK with the returned object:

```ts
import OpenAI from "openai"

const openai = new OpenAI()

const joke = await openai.chat.completions.create(openAiBody)
```

Using this method, you're getting all of the power of Langtail prompts (like variables) *and* you're able to send requests directly to OpenAI. This can be helpful if you're especially sensitive to performance. If you're taking this route for security reasons, [let us know](/support/get-help) and give you a deeper look into Langtail.

# API reference

## LangtailNode

### Constructor

The constructor accepts an options object with the following properties:

- `apiKey`: The API key for Langtail. This is required.
- `baseURL`(optional): The base URL for the Langtail API.
- `doNotRecord`(optional): A boolean indicating whether to record the API calls.
- `organization`(optional): The organization ID.
- `project`(optional): The project ID.
- `fetch`(optional): The fetch function to use for making HTTP requests. [It is passed to openAI client under the hood](https://github.com/openai/openai-node?tab=readme-ov-file#customizing-the-fetch-client).

### Properties

- `completions`: An instance of the `LangtailPrompts` class.
- `chat`: An object containing a `completions` object with a `create` method.

### Methods

#### chat.completions.create

This method accepts two parameters:

- `body`: An object that can be of type `ChatCompletionCreateParamsNonStreaming & ILangtailExtraProps`, `ChatCompletionCreateParamsStreaming & ILangtailExtraProps`, `ChatCompletionCreateParamsBase & ILangtailExtraProps`, or `ChatCompletionCreateParams & ILangtailExtraProps`.
- `options`(optional): OpenAI `Core.RequestOptions` object

It returns a promise that resolves to a `ChatCompletion` or a `Stream<ChatCompletionChunk>` depending whether you are using streaming or not.

### Exceptions

- Throws an error if the `apiKey` is not provided in the options object or as an environment variable.

## LangtailPrompts

### Constructor

The constructor accepts an options object with the following properties:

- `apiKey`: The API key for Langtail. This is required.
- `baseURL`(optional): The base URL for the Langtail API.
- `organization`(optional): The organization ID.
- `project`(optional): The project ID.
- `fetch`(optional): The fetch function to use for making HTTP requests. [It is passed to openAI client under the hood](https://github.com/openai/openai-node?tab=readme-ov-file#customizing-the-fetch-client).

### Properties

- `apiKey`: The API key for Langtail.
- `baseUrl`(optional): The base URL for the Langtail API.
- `options`(optional): An object containing the options for the Langtail API.

### Methods

#### invoke

This method accepts an `IRequestParams` or `IRequestParamsStream` object and returns a promise that resolves to an `OpenAIResponseWithHttp` or a `StreamResponseType` depending on whether you use streaming or not.

### get

This method accepts one parameter with these fields:

- `prompt`: A string representing the prompt.
- `environment`(optional): An `Environment` string identifier. Accepts values: `"preview" | "staging" | "production"`. Defaults to `production`
- `version`(optional): string for version. Necessary for preview environment

Returns playground state defined here: https://github.com/langtail/langtail-node/blob/48e2690749e26d61c2e43b1bf6ac92e7d4fef48b/src/schemas.ts#L94

### Exceptions

- Throws an error if the fetch operation fails.
- Throws an error if there is no body in the response when streaming is enabled.
